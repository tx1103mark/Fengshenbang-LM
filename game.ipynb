{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/Fengshenbang-LM/blob/main/game.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "cur_path=$(cd $(dirname $0); pwd)\n",
        "echo \"current path: $cur_path\"\n",
        "ALGO_PATH=$cur_path\n",
        "export WANDB_DISABLED=true\n",
        "\n",
        "base_path=/opt/huawei/explorer-env\n",
        "base_path=/home/ma-user/work\n",
        "\n",
        "model_path=$base_path/dataset/nlp_large_model_new/openLLM/glm-4-9b-chat/\n",
        "# model_path=/opt/huawei/explorer-env/dataset/nlp_large_model_new/instruct_finetune/0614_searchllm_code_1ep\n",
        "# dataset_dir=/home/ma-user/work/dataset/g00495223/instruct_tuning/data/sub_questions/\n",
        "dataset_dir=/home/ma-user/work/dataset/nlp_large_data/z00421835/round1_training_data/\n",
        "dataset_name=game\n",
        "cutoff_len=4096\n",
        "\n",
        "\n",
        "output_dir=/home/ma-user/work/dataset/nlp_large_model_new/z00421835/model_save/glm4_test \\\n",
        "script_path=$ALGO_PATH/src/train.py\n",
        "ds_config_path=$ALGO_PATH/ds_config2.json\n",
        "\n",
        "\n",
        "DISTRIBUTED_ARGS=\"--nproc_per_node  --nnodes $NNODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n",
        "\n",
        "echo \"##DISTRIBUTED_ARGS:$DISTRIBUTED_ARGS\"\n",
        "    # --quantization_bit 4 \\\n",
        "export TOKENIZERS_PARALLELISM=false\n",
        "# python -m torch.distributed.run --nproc_per_node=$NGPUS_PER_NODE --nnode=$NNODES --node_rank=$NODE_RANK --master_addr=$MASTER_ADDR --master_port=$MASTER_PORT\n",
        "# python ${cur_path}/src/train_bash.py \\\n",
        "torchrun $script_path \\\n",
        "    --deepspeed ds_config2.json \\\n",
        "    --stage sft \\\n",
        "    --model_name_or_path $model_path \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --eval_steps 10 \\\n",
        "    --val_size 0.05 \\\n",
        "    --evaluation_strategy=steps \\\n",
        "    --dataset_dir  $dataset_dir\\\n",
        "    --dataset  $dataset_name \\\n",
        "    --template glm4 \\\n",
        "    --finetuning_type lora \\\n",
        "    --lora_target query_key_value \\\n",
        "    --output_dir $output_dir \\\n",
        "    --cache_dir /cache \\\n",
        "    --cutoff_len $cutoff_len \\\n",
        "    --flash_attn sdpa \\\n",
        "    --gradient_checkpointing true \\\n",
        "    --overwrite_output_dir \\\n",
        "    --per_device_train_batch_size 1 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 64 \\\n",
        "    --lr_scheduler_type cosine \\\n",
        "    --logging_steps 1 \\\n",
        "    --logging_dir log_dir \\\n",
        "    --save_strategy epoch \\\n",
        "    --learning_rate 5e-5 \\\n",
        "    --num_train_epochs 3.0 \\\n",
        "    --plot_loss \\\n",
        "    --fp16\n"
      ],
      "metadata": {
        "id": "iEmbI49o0Fw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "cur_path=$(cd $(dirname $0); pwd)\n",
        "echo \"current path: $cur_path\"\n",
        "ALGO_PATH=$cur_path\n",
        "export WANDB_DISABLED=true\n",
        "\n",
        "echo \"开始安装环境\"\n",
        "date\n",
        "cp /opt/huawei/dataset/model_dir/z00421835/envs/swift.tar.gz /cache/\n",
        "tar -xzf /cache/swift.tar.gz  -C /cache/\n",
        "date\n",
        "source /cache/bin/activate\n",
        "echo \"结束安装环境\"\n",
        "\n",
        "\n",
        "pip install -U transformers -i  http://pip.modelarts.private.com/repository/pypi/simple/ --trusted-host pip.modelarts.private.com\n",
        "\n",
        "pip install accelerate==0.30.1  -i  http://pip.modelarts.private.com/repository/pypi/simple/ --trusted-host pip.modelarts.private.com\n",
        "\n",
        "model_path=/opt/huawei/dataset/model_dir/openLLM/Qwen1.5-14B-Chat/\n",
        "# model_path=/opt/huawei/explorer-env/dataset/nlp_large_model_new/instruct_finetune/0614_searchllm_code_1ep\n",
        "# dataset_dir=/home/ma-user/work/dataset/g00495223/instruct_tuning/data/sub_questions/\n",
        "dataset_dir=/opt/huawei/dataset/data_dir/z00421835/round1_training_data/\n",
        "dataset_name=game\n",
        "cutoff_len=4096\n",
        "\n",
        "\n",
        "output_dir=/opt/huawei/dataset/model_dir/z00421835/model_save/qwen14b_mtp \\\n",
        "script_path=$ALGO_PATH/src/train.py\n",
        "ds_config_path=$ALGO_PATH/ds_config2.json\n",
        "\n",
        "# 系统默认环境变量，不建议修改\n",
        "MASTER_HOST=\"$VC_WORKER_HOSTS\"\n",
        "MASTER_ADDR=\"${VC_WORKER_HOSTS%%,*}\"\n",
        "MASTER_PORT=\"6060\"\n",
        "JOB_ID=\"1234\"\n",
        "NNODES=\"$MA_NUM_HOSTS\"\n",
        "NODE_RANK=\"$VC_TASK_INDEX\"\n",
        "NGPUS_PER_NODE=\"$MA_NUM_GPUS\"\n",
        "if [[ $NODE_RANK == 0 ]]; then\n",
        "    EXT_ARGS=\"--rdzv_conf=is_host=1\"\n",
        "else\n",
        "    EXT_ARGS=\"\"\n",
        "fi\n",
        "DISTRIBUTED_ARGS=\"--nproc_per_node  --nnodes $NNODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT\"\n",
        "\n",
        "echo \"##DISTRIBUTED_ARGS:$DISTRIBUTED_ARGS\"\n",
        "    # --quantization_bit 4 \\\n",
        "export TOKENIZERS_PARALLELISM=false\n",
        "# python -m torch.distributed.run --nproc_per_node=$NGPUS_PER_NODE --nnode=$NNODES --node_rank=$NODE_RANK --master_addr=$MASTER_ADDR --master_port=$MASTER_PORT\n",
        "# python ${cur_path}/src/train_bash.py \\\n",
        "python -m torch.distributed.run --nproc_per_node=$NGPUS_PER_NODE --nnode=$NNODES --node_rank=$NODE_RANK --master_addr=$MASTER_ADDR --master_port=$MASTER_PORT $script_path \\\n",
        "    --deepspeed $ALGO_PATH/ds_config_zero3_test.json \\\n",
        "    --stage sft \\\n",
        "    --model_name_or_path $model_path \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --eval_steps 10 \\\n",
        "    --val_size 0.05 \\\n",
        "    --evaluation_strategy=steps \\\n",
        "    --dataset_dir  $dataset_dir\\\n",
        "    --dataset  $dataset_name \\\n",
        "    --template qwen \\\n",
        "    --finetuning_type lora \\\n",
        "    --output_dir $output_dir \\\n",
        "    --cache_dir /cache \\\n",
        "    --cutoff_len $cutoff_len \\\n",
        "    --flash_attn sdpa \\\n",
        "    --gradient_checkpointing true \\\n",
        "    --overwrite_output_dir \\\n",
        "    --per_device_train_batch_size 2 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --gradient_accumulation_steps 8 \\\n",
        "    --lr_scheduler_type cosine \\\n",
        "    --logging_steps 1 \\\n",
        "    --logging_dir log_dir \\\n",
        "    --save_strategy epoch \\\n",
        "    --learning_rate 5e-5 \\\n",
        "    --num_train_epochs 3.0 \\\n",
        "    --plot_loss \\\n",
        "    --fp16\n"
      ],
      "metadata": {
        "id": "55XaWUt-kS3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"train_batch_size\": \"auto\",\n",
        "  \"train_micro_batch_size_per_gpu\": \"auto\",\n",
        "  \"gradient_accumulation_steps\": \"auto\",\n",
        "  \"gradient_clipping\": \"auto\",\n",
        "  \"zero_allow_untested_optimizer\": true,\n",
        "  \"flops_profiler\": {\n",
        "        \"enabled\": false,\n",
        "        \"profile_step\": 20,\n",
        "        \"module_depth\": -1,\n",
        "        \"top_modules\": 1,\n",
        "        \"detailed\": true,\n",
        "        \"output_file\": \"profile.log\"\n",
        "   },\n",
        "  \"fp16\": {\n",
        "    \"enabled\": true,\n",
        "    \"loss_scale\": 0,\n",
        "    \"loss_scale_window\": 1000,\n",
        "    \"initial_scale_power\": 16,\n",
        "    \"hysteresis\": 2,\n",
        "    \"min_loss_scale\": 1\n",
        "  },\n",
        "  \"bf16\": {\n",
        "    \"enabled\": \"auto\"\n",
        "  },\n",
        "  \"zero_optimization\": {\n",
        "    \"stage\": 2,\n",
        "    \"offload_optimizer\": {\n",
        "      \"device\": \"cpu\",\n",
        "      \"pin_memory\": true\n",
        "    },\n",
        "    \"allgather_partitions\": true,\n",
        "    \"allgather_bucket_size\": 5e8,\n",
        "    \"overlap_comm\": true,\n",
        "    \"reduce_scatter\": true,\n",
        "    \"reduce_bucket_size\": 5e8,\n",
        "    \"contiguous_gradients\": true,\n",
        "    \"round_robin_gradients\": true\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "gHif5pUy0ey0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}